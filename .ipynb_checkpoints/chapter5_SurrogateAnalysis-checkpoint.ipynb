{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 대리 분석\n",
    "\n",
    "XAI에서 대리 분석은 본래 인공지능 모델이 너무 복잡해서 분석이 불가능할 때 \n",
    "\n",
    "유사한 기능을 흉내 내는 인공지능 모델 여러 개를 대리로 만들어서 본래 모델을 분석하는 기법이다.\n",
    "\n",
    "<br>\n",
    "\n",
    "대리 분석법의 핵심 이론은 이렇다.\n",
    "\n",
    "대리 분석 모델은 f를 흉내내는 모델 g를 만든다. 이 둘은 학습 방식이 다를 수도, 같을 수도 있다.\n",
    "\n",
    "모델 f를 학습시킬 때처럼 학습 데이터 전부를 모델 g를 학습하는 데 사용하거나,\n",
    "\n",
    "데이터를 라벨별로 또는 일부만 추려서 모델 g를 학습시키는 것이다.\n",
    "\n",
    "g는 설명 가능하기 때문에 원래 모델이 어떻게 학습됐을지 간단하게라도 해석할 수 있다.\n",
    "\n",
    "<br>\n",
    "\n",
    "학습 데이터(일부 또는 전체)를 사용해서 대리 분석 모델을 구축할 경우,\n",
    "\n",
    "이것을 글로벌 대리 분석(Global Surrogate Analysis)라고 한다.\n",
    "\n",
    "학습 데이터 하나를 해석하는 과정을\n",
    "\n",
    "로컬 대리 분석(Local Surrogate Analysis)라고 부른다.\n",
    "\n",
    "<br>\n",
    "\n",
    "이 기법의 가장 큰 장점은 모델 애그노스틱(agnostic, 모델에 대한 지식 없이도 학습할 수 있음)하다는 것이다.\n",
    "\n",
    "또한, 적은 학습 데이터로도 설명 가능한 모델을 만들 수 있다. \n",
    "\n",
    "필요한 것은 데이터와 예측 모델뿐이다.\n",
    "\n",
    "중간에 예측 모델 f가 바뀌더라도 피처만 같다면 대리 분석을 수행할 수 있다.\n",
    "\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 글로벌 대리 분석\n",
    "\n",
    "전체 학습 데이터를 사용해 블랙박스 함수 f를 따라하는 유사 함수 g를 만들고\n",
    "\n",
    "g를 해석 가능하도록 변조하는 방법이다. 이때 함수 g는 설명 가능해야 한다.\n",
    "\n",
    "g의 예: 선형 회귀, 로지스틱 회귀, 의사 결정 트리, 나이브 베이즈, K-최근접 이웃\n",
    "\n",
    "글로벌 대리 분석을 수행하는 과정은 다음과 같다.\n",
    "\n",
    "1. 데이터 집합 x를 선택한다. 이것은 학습 데이터 전체일 수도 있고 일부일 수도 있다.\n",
    "\n",
    "2. 선택한 데이터 집합 x에 대해 블랙박스 모델 f의 예측 결과를 구한다.\n",
    "\n",
    "3. XAI 모델을 고른다. 학습한 결과를 모델 g라고 부른다.\n",
    "\n",
    "4. 모델 g는 설명 가능해야 한다.\n",
    "\n",
    "5. 데이터 집합 x로 모델 g를 학습시킨다.\n",
    "\n",
    "6. 데이터 x에 대해 모델 f가 예측한 결과와 모델 g의 예측 결과를 비교하면서 두 모델이 최대한 유사한 결과를 내도록 튜닝한다.\n",
    "\n",
    "7. 6과정이 끝나면 설명 가능한 모델 g를 XAI기법을 사용해 해석한다.\n",
    "\n",
    "6번 과정에 대해 두 모델 간 비교를 R 스퀘어 방식으로 측정한다면\n",
    "\n",
    "SSE(Sum of Squares Error), SST(Sum of Squares Total)의 차이를 통해 얼마나 근사한지 측정할 수 있다.\n",
    "\n",
    "<br>\n",
    "\n",
    "글로벌 대리 분석의 장점은 다음과 같다.\n",
    "\n",
    "다양한 XAI 기법을 자유롭게 적용할 수 있을 뿐만 아니라 블랙박스 모델을 이해하지 않아도 어떻게 학습됐는지 설명할 수 있다.\n",
    "\n",
    "대리 분석에 사용하는 머신러닝 기법은 구현이 쉽고 설명이 가능하다.\n",
    "\n",
    "<br>\n",
    "\n",
    "대리 분석을 수행할 때 주의할 점으로\n",
    "\n",
    "유사하게 설명하는 모델로써 g 모델의 정확도와 해석 방향에 결함이 있을 수 있다.\n",
    "\n",
    "또한 유사함을 결정짓는 measure function의 설명 가능성 판단 기준이 주관적이다.\n",
    "\n",
    "마지막으로 학습 데이터에 편향됐을 위험이 있다. \n",
    "\n",
    "<br>\n",
    "\n",
    "글로벌 대리 분성은 전통적인 머신러닝 기법에 적용하기 좋다.\n",
    "\n",
    "만약 SVM을 분석하려고 한다면\n",
    "\n",
    "SVM의 의사 결정 결과를 모방하는 의사 결정 트리를 만들고 이를 시각화하여 결정 과정을 해석할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 로컬 대리 분석\n",
    "\n",
    "데이터 하나에 대해 블랙박스가 해석하는 과정을 분석하는 기법이다.\n",
    "\n",
    "이 기법은 LIME(Local Interpretable Model-agnostic Explanations)라는 이름으로 더 알려져 있다.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
